; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -march=amdgcn -mcpu=gfx90a -verify-machineinstrs -misched-cluster=0 -amdgpu-igrouplp-exact-solver=1 -amdgpu-igrouplp-exact-solver-max-branches=100000 -amdgpu-igrouplp-exact-solver-sg-priority-heur=dep < %s | FileCheck -check-prefix=DEPHEUR %s
; RUN: llc -march=amdgcn -mcpu=gfx90a -verify-machineinstrs -misched-cluster=0 -amdgpu-igrouplp-exact-solver=1 -amdgpu-igrouplp-exact-solver-max-branches=100000 -amdgpu-igrouplp-exact-solver-sg-priority-heur=cost < %s | FileCheck -check-prefix=COSTHEUR %s
; RUN: llc -march=amdgcn -mcpu=gfx90a -verify-machineinstrs -misched-cluster=0 -amdgpu-igrouplp-exact-solver=1 -amdgpu-igrouplp-exact-solver-max-branches=100000 -amdgpu-igrouplp-exact-solver-sg-priority-heur=order < %s | FileCheck -check-prefix=ORDERHEUR %s




define amdgpu_kernel void @test_sched_group_barrier_pipeline_alternating_READ_VALU_WRITE(<32 x i32> addrspace(1)* noalias %in, <32 x i32> addrspace(1)* noalias %out) #0 {
; DEPHEUR-LABEL: test_sched_group_barrier_pipeline_alternating_READ_VALU_WRITE:
; DEPHEUR:       ; %bb.0:
; DEPHEUR-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x24
; DEPHEUR-NEXT:    v_lshlrev_b32_e32 v16, 7, v0
; DEPHEUR-NEXT:    s_waitcnt lgkmcnt(0)
; DEPHEUR-NEXT:    global_load_dwordx4 v[12:15], v16, s[0:1] offset:48
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; DEPHEUR-NEXT:    s_waitcnt vmcnt(0)
; DEPHEUR-NEXT:    v_mul_lo_u32 v13, v13, v13
; DEPHEUR-NEXT:    v_mul_lo_u32 v12, v12, v12
; DEPHEUR-NEXT:    v_mul_lo_u32 v15, v15, v15
; DEPHEUR-NEXT:    v_mul_lo_u32 v14, v14, v14
; DEPHEUR-NEXT:    global_store_dwordx4 v16, v[12:15], s[2:3] offset:48
; DEPHEUR-NEXT:    global_load_dwordx4 v[0:3], v16, s[0:1]
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; DEPHEUR-NEXT:    s_waitcnt vmcnt(0)
; DEPHEUR-NEXT:    v_mul_lo_u32 v3, v3, v3
; DEPHEUR-NEXT:    v_mul_lo_u32 v2, v2, v2
; DEPHEUR-NEXT:    global_load_dwordx4 v[8:11], v16, s[0:1] offset:32
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; DEPHEUR-NEXT:    s_waitcnt vmcnt(0)
; DEPHEUR-NEXT:    v_mul_lo_u32 v9, v9, v9
; DEPHEUR-NEXT:    v_mul_lo_u32 v8, v8, v8
; DEPHEUR-NEXT:    v_mul_lo_u32 v11, v11, v11
; DEPHEUR-NEXT:    v_mul_lo_u32 v10, v10, v10
; DEPHEUR-NEXT:    global_store_dwordx4 v16, v[8:11], s[2:3] offset:32
; DEPHEUR-NEXT:    global_load_dwordx4 v[4:7], v16, s[0:1] offset:112
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; DEPHEUR-NEXT:    s_waitcnt vmcnt(0)
; DEPHEUR-NEXT:    v_mul_lo_u32 v7, v7, v7
; DEPHEUR-NEXT:    v_mul_lo_u32 v6, v6, v6
; DEPHEUR-NEXT:    v_mul_lo_u32 v1, v1, v1
; DEPHEUR-NEXT:    v_mul_lo_u32 v0, v0, v0
; DEPHEUR-NEXT:    global_store_dwordx4 v16, v[0:3], s[2:3]
; DEPHEUR-NEXT:    global_load_dwordx4 v[0:3], v16, s[0:1] offset:80
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; DEPHEUR-NEXT:    s_waitcnt vmcnt(0)
; DEPHEUR-NEXT:    v_mul_lo_u32 v3, v3, v3
; DEPHEUR-NEXT:    v_mul_lo_u32 v2, v2, v2
; DEPHEUR-NEXT:    v_mul_lo_u32 v1, v1, v1
; DEPHEUR-NEXT:    v_mul_lo_u32 v0, v0, v0
; DEPHEUR-NEXT:    global_store_dwordx4 v16, v[0:3], s[2:3] offset:80
; DEPHEUR-NEXT:    v_mul_lo_u32 v5, v5, v5
; DEPHEUR-NEXT:    v_mul_lo_u32 v4, v4, v4
; DEPHEUR-NEXT:    global_store_dwordx4 v16, v[4:7], s[2:3] offset:112
; DEPHEUR-NEXT:    global_load_dwordx4 v[4:7], v16, s[0:1] offset:96
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; DEPHEUR-NEXT:    s_waitcnt vmcnt(0)
; DEPHEUR-NEXT:    v_mul_lo_u32 v7, v7, v7
; DEPHEUR-NEXT:    global_load_dwordx4 v[0:3], v16, s[0:1] offset:64
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; DEPHEUR-NEXT:    s_waitcnt vmcnt(0)
; DEPHEUR-NEXT:    v_mul_lo_u32 v3, v3, v3
; DEPHEUR-NEXT:    v_mul_lo_u32 v2, v2, v2
; DEPHEUR-NEXT:    v_mul_lo_u32 v1, v1, v1
; DEPHEUR-NEXT:    v_mul_lo_u32 v0, v0, v0
; DEPHEUR-NEXT:    global_store_dwordx4 v16, v[0:3], s[2:3] offset:64
; DEPHEUR-NEXT:    v_mul_lo_u32 v6, v6, v6
; DEPHEUR-NEXT:    v_mul_lo_u32 v5, v5, v5
; DEPHEUR-NEXT:    v_mul_lo_u32 v4, v4, v4
; DEPHEUR-NEXT:    global_store_dwordx4 v16, v[4:7], s[2:3] offset:96
; DEPHEUR-NEXT:    global_load_dwordx4 v[4:7], v16, s[0:1] offset:16
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; DEPHEUR-NEXT:    s_waitcnt vmcnt(0)
; DEPHEUR-NEXT:    v_mul_lo_u32 v5, v5, v5
; DEPHEUR-NEXT:    v_mul_lo_u32 v4, v4, v4
; DEPHEUR-NEXT:    v_mul_lo_u32 v7, v7, v7
; DEPHEUR-NEXT:    v_mul_lo_u32 v6, v6, v6
; DEPHEUR-NEXT:    global_store_dwordx4 v16, v[4:7], s[2:3] offset:16
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; DEPHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; DEPHEUR-NEXT:    s_endpgm
;
; COSTHEUR-LABEL: test_sched_group_barrier_pipeline_alternating_READ_VALU_WRITE:
; COSTHEUR:       ; %bb.0:
; COSTHEUR-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x24
; COSTHEUR-NEXT:    v_lshlrev_b32_e32 v12, 7, v0
; COSTHEUR-NEXT:    s_waitcnt lgkmcnt(0)
; COSTHEUR-NEXT:    global_load_dwordx4 v[8:11], v12, s[0:1] offset:64
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; COSTHEUR-NEXT:    s_waitcnt vmcnt(0)
; COSTHEUR-NEXT:    v_mul_lo_u32 v11, v11, v11
; COSTHEUR-NEXT:    v_mul_lo_u32 v10, v10, v10
; COSTHEUR-NEXT:    v_mul_lo_u32 v9, v9, v9
; COSTHEUR-NEXT:    v_mul_lo_u32 v8, v8, v8
; COSTHEUR-NEXT:    global_store_dwordx4 v12, v[8:11], s[2:3] offset:64
; COSTHEUR-NEXT:    global_load_dwordx4 v[0:3], v12, s[0:1]
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; COSTHEUR-NEXT:    s_waitcnt vmcnt(0)
; COSTHEUR-NEXT:    v_mul_lo_u32 v3, v3, v3
; COSTHEUR-NEXT:    v_mul_lo_u32 v2, v2, v2
; COSTHEUR-NEXT:    global_load_dwordx4 v[8:11], v12, s[0:1] offset:32
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; COSTHEUR-NEXT:    s_waitcnt vmcnt(0)
; COSTHEUR-NEXT:    v_mul_lo_u32 v9, v9, v9
; COSTHEUR-NEXT:    v_mul_lo_u32 v8, v8, v8
; COSTHEUR-NEXT:    v_mul_lo_u32 v11, v11, v11
; COSTHEUR-NEXT:    v_mul_lo_u32 v10, v10, v10
; COSTHEUR-NEXT:    global_store_dwordx4 v12, v[8:11], s[2:3] offset:32
; COSTHEUR-NEXT:    global_load_dwordx4 v[4:7], v12, s[0:1] offset:112
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; COSTHEUR-NEXT:    s_waitcnt vmcnt(0)
; COSTHEUR-NEXT:    v_mul_lo_u32 v7, v7, v7
; COSTHEUR-NEXT:    v_mul_lo_u32 v6, v6, v6
; COSTHEUR-NEXT:    v_mul_lo_u32 v1, v1, v1
; COSTHEUR-NEXT:    v_mul_lo_u32 v0, v0, v0
; COSTHEUR-NEXT:    global_store_dwordx4 v12, v[0:3], s[2:3]
; COSTHEUR-NEXT:    global_load_dwordx4 v[0:3], v12, s[0:1] offset:96
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; COSTHEUR-NEXT:    s_waitcnt vmcnt(0)
; COSTHEUR-NEXT:    v_mul_lo_u32 v3, v3, v3
; COSTHEUR-NEXT:    v_mul_lo_u32 v2, v2, v2
; COSTHEUR-NEXT:    v_mul_lo_u32 v1, v1, v1
; COSTHEUR-NEXT:    v_mul_lo_u32 v0, v0, v0
; COSTHEUR-NEXT:    global_store_dwordx4 v12, v[0:3], s[2:3] offset:96
; COSTHEUR-NEXT:    global_load_dwordx4 v[0:3], v12, s[0:1] offset:80
; COSTHEUR-NEXT:    s_waitcnt vmcnt(0)
; COSTHEUR-NEXT:    v_mul_lo_u32 v3, v3, v3
; COSTHEUR-NEXT:    v_mul_lo_u32 v2, v2, v2
; COSTHEUR-NEXT:    v_mul_lo_u32 v1, v1, v1
; COSTHEUR-NEXT:    v_mul_lo_u32 v0, v0, v0
; COSTHEUR-NEXT:    global_store_dwordx4 v12, v[0:3], s[2:3] offset:80
; COSTHEUR-NEXT:    v_mul_lo_u32 v5, v5, v5
; COSTHEUR-NEXT:    v_mul_lo_u32 v4, v4, v4
; COSTHEUR-NEXT:    global_store_dwordx4 v12, v[4:7], s[2:3] offset:112
; COSTHEUR-NEXT:    global_load_dwordx4 v[4:7], v12, s[0:1] offset:48
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; COSTHEUR-NEXT:    s_waitcnt vmcnt(0)
; COSTHEUR-NEXT:    v_mul_lo_u32 v5, v5, v5
; COSTHEUR-NEXT:    global_load_dwordx4 v[0:3], v12, s[0:1] offset:16
; COSTHEUR-NEXT:    v_mul_lo_u32 v4, v4, v4
; COSTHEUR-NEXT:    s_waitcnt vmcnt(0)
; COSTHEUR-NEXT:    v_mul_lo_u32 v1, v1, v1
; COSTHEUR-NEXT:    v_mul_lo_u32 v0, v0, v0
; COSTHEUR-NEXT:    v_mul_lo_u32 v3, v3, v3
; COSTHEUR-NEXT:    v_mul_lo_u32 v2, v2, v2
; COSTHEUR-NEXT:    global_store_dwordx4 v12, v[0:3], s[2:3] offset:16
; COSTHEUR-NEXT:    v_mul_lo_u32 v7, v7, v7
; COSTHEUR-NEXT:    v_mul_lo_u32 v6, v6, v6
; COSTHEUR-NEXT:    global_store_dwordx4 v12, v[4:7], s[2:3] offset:48
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; COSTHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; COSTHEUR-NEXT:    s_endpgm
;
; ORDERHEUR-LABEL: test_sched_group_barrier_pipeline_alternating_READ_VALU_WRITE:
; ORDERHEUR:       ; %bb.0:
; ORDERHEUR-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x24
; ORDERHEUR-NEXT:    v_lshlrev_b32_e32 v16, 7, v0
; ORDERHEUR-NEXT:    ; kill: killed $sgpr0_sgpr1
; ORDERHEUR-NEXT:    s_waitcnt lgkmcnt(0)
; ORDERHEUR-NEXT:    global_load_dwordx4 v[0:3], v16, s[0:1]
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; ORDERHEUR-NEXT:    s_waitcnt vmcnt(0)
; ORDERHEUR-NEXT:    v_mul_lo_u32 v3, v3, v3
; ORDERHEUR-NEXT:    v_mul_lo_u32 v2, v2, v2
; ORDERHEUR-NEXT:    v_mul_lo_u32 v1, v1, v1
; ORDERHEUR-NEXT:    v_mul_lo_u32 v0, v0, v0
; ORDERHEUR-NEXT:    global_store_dwordx4 v16, v[0:3], s[2:3]
; ORDERHEUR-NEXT:    global_load_dwordx4 v[0:3], v16, s[0:1] offset:112
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; ORDERHEUR-NEXT:    s_waitcnt vmcnt(0)
; ORDERHEUR-NEXT:    v_mul_lo_u32 v3, v3, v3
; ORDERHEUR-NEXT:    v_mul_lo_u32 v2, v2, v2
; ORDERHEUR-NEXT:    v_mul_lo_u32 v1, v1, v1
; ORDERHEUR-NEXT:    v_mul_lo_u32 v0, v0, v0
; ORDERHEUR-NEXT:    global_store_dwordx4 v16, v[0:3], s[2:3] offset:112
; ORDERHEUR-NEXT:    global_load_dwordx4 v[0:3], v16, s[0:1] offset:96
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; ORDERHEUR-NEXT:    s_waitcnt vmcnt(0)
; ORDERHEUR-NEXT:    v_mul_lo_u32 v3, v3, v3
; ORDERHEUR-NEXT:    v_mul_lo_u32 v2, v2, v2
; ORDERHEUR-NEXT:    v_mul_lo_u32 v1, v1, v1
; ORDERHEUR-NEXT:    v_mul_lo_u32 v0, v0, v0
; ORDERHEUR-NEXT:    global_store_dwordx4 v16, v[0:3], s[2:3] offset:96
; ORDERHEUR-NEXT:    global_load_dwordx4 v[4:7], v16, s[0:1] offset:48
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; ORDERHEUR-NEXT:    s_waitcnt vmcnt(0)
; ORDERHEUR-NEXT:    v_mul_lo_u32 v5, v5, v5
; ORDERHEUR-NEXT:    v_mul_lo_u32 v4, v4, v4
; ORDERHEUR-NEXT:    v_mul_lo_u32 v7, v7, v7
; ORDERHEUR-NEXT:    v_mul_lo_u32 v6, v6, v6
; ORDERHEUR-NEXT:    global_store_dwordx4 v16, v[4:7], s[2:3] offset:48
; ORDERHEUR-NEXT:    global_load_dwordx4 v[8:11], v16, s[0:1] offset:16
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; ORDERHEUR-NEXT:    s_nop 0
; ORDERHEUR-NEXT:    global_load_dwordx4 v[4:7], v16, s[0:1] offset:64
; ORDERHEUR-NEXT:    s_waitcnt vmcnt(0)
; ORDERHEUR-NEXT:    v_mul_lo_u32 v7, v7, v7
; ORDERHEUR-NEXT:    v_mul_lo_u32 v6, v6, v6
; ORDERHEUR-NEXT:    v_mul_lo_u32 v5, v5, v5
; ORDERHEUR-NEXT:    v_mul_lo_u32 v4, v4, v4
; ORDERHEUR-NEXT:    global_store_dwordx4 v16, v[4:7], s[2:3] offset:64
; ORDERHEUR-NEXT:    v_mul_lo_u32 v9, v9, v9
; ORDERHEUR-NEXT:    global_load_dwordx4 v[12:15], v16, s[0:1] offset:32
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; ORDERHEUR-NEXT:    s_waitcnt vmcnt(0)
; ORDERHEUR-NEXT:    v_mul_lo_u32 v13, v13, v13
; ORDERHEUR-NEXT:    v_mul_lo_u32 v12, v12, v12
; ORDERHEUR-NEXT:    v_mul_lo_u32 v15, v15, v15
; ORDERHEUR-NEXT:    v_mul_lo_u32 v14, v14, v14
; ORDERHEUR-NEXT:    global_store_dwordx4 v16, v[12:15], s[2:3] offset:32
; ORDERHEUR-NEXT:    v_mul_lo_u32 v8, v8, v8
; ORDERHEUR-NEXT:    v_mul_lo_u32 v11, v11, v11
; ORDERHEUR-NEXT:    v_mul_lo_u32 v10, v10, v10
; ORDERHEUR-NEXT:    global_store_dwordx4 v16, v[8:11], s[2:3] offset:16
; ORDERHEUR-NEXT:    global_load_dwordx4 v[8:11], v16, s[0:1] offset:80
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000020) size(1) SyncID(0)
; ORDERHEUR-NEXT:    s_waitcnt vmcnt(0)
; ORDERHEUR-NEXT:    v_mul_lo_u32 v11, v11, v11
; ORDERHEUR-NEXT:    v_mul_lo_u32 v10, v10, v10
; ORDERHEUR-NEXT:    v_mul_lo_u32 v9, v9, v9
; ORDERHEUR-NEXT:    v_mul_lo_u32 v8, v8, v8
; ORDERHEUR-NEXT:    global_store_dwordx4 v16, v[8:11], s[2:3] offset:80
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000002) size(2) SyncID(0)
; ORDERHEUR-NEXT:    ; sched_group_barrier mask(0x00000040) size(1) SyncID(0)
; ORDERHEUR-NEXT:    s_endpgm
  %tid = call i32 @llvm.amdgcn.workitem.id.x() #2
  %gep1 = getelementptr <32 x i32>, <32 x i32> addrspace(1)* %in, i32 %tid
  %load = load <32 x i32>, <32 x i32> addrspace(1)* %gep1
  %mul = mul <32 x i32> %load, %load
  %gep2 = getelementptr <32 x i32>, <32 x i32> addrspace(1)* %out, i32 %tid
  store <32 x i32> %mul, <32 x i32> addrspace(1)* %gep2
  ; 1 VMEM read
  call void @llvm.amdgcn.sched.group.barrier(i32 32, i32 1, i32 0)
  ; 2 VALU
  call void @llvm.amdgcn.sched.group.barrier(i32 2, i32 2, i32 0)
  ; 1 VMEM write
  call void @llvm.amdgcn.sched.group.barrier(i32 64, i32 1, i32 0)
  ; 1 VMEM read
  call void @llvm.amdgcn.sched.group.barrier(i32 32, i32 1, i32 0)
  ; 2 VALU
  call void @llvm.amdgcn.sched.group.barrier(i32 2, i32 2, i32 0)
  ; 1 VMEM write
  call void @llvm.amdgcn.sched.group.barrier(i32 64, i32 1, i32 0)
  ; 1 VMEM read
  call void @llvm.amdgcn.sched.group.barrier(i32 32, i32 1, i32 0)
  ; 2 VALU
  call void @llvm.amdgcn.sched.group.barrier(i32 2, i32 2, i32 0)
  ; 1 VMEM write
  call void @llvm.amdgcn.sched.group.barrier(i32 64, i32 1, i32 0)
  ; 1 VMEM read
  call void @llvm.amdgcn.sched.group.barrier(i32 32, i32 1, i32 0)
  ; 2 VALU
  call void @llvm.amdgcn.sched.group.barrier(i32 2, i32 2, i32 0)
  ; 1 VMEM write
  call void @llvm.amdgcn.sched.group.barrier(i32 64, i32 1, i32 0)
  ; 1 VMEM read
  call void @llvm.amdgcn.sched.group.barrier(i32 32, i32 1, i32 0)
  ; 2 VALU
  call void @llvm.amdgcn.sched.group.barrier(i32 2, i32 2, i32 0)
  ; 1 VMEM write
  call void @llvm.amdgcn.sched.group.barrier(i32 64, i32 1, i32 0)
  ; 1 VMEM read
  call void @llvm.amdgcn.sched.group.barrier(i32 32, i32 1, i32 0)
  ; 2 VALU
  call void @llvm.amdgcn.sched.group.barrier(i32 2, i32 2, i32 0)
  ; 1 VMEM write
  call void @llvm.amdgcn.sched.group.barrier(i32 64, i32 1, i32 0)
  ; 1 VMEM read
  call void @llvm.amdgcn.sched.group.barrier(i32 32, i32 1, i32 0)
  ; 2 VALU
  call void @llvm.amdgcn.sched.group.barrier(i32 2, i32 2, i32 0)
  ; 1 VMEM write
  call void @llvm.amdgcn.sched.group.barrier(i32 64, i32 1, i32 0)
  ; 1 VMEM read
  call void @llvm.amdgcn.sched.group.barrier(i32 32, i32 1, i32 0)
  ; 2 VALU
  call void @llvm.amdgcn.sched.group.barrier(i32 2, i32 2, i32 0)
  ; 1 VMEM write
  call void @llvm.amdgcn.sched.group.barrier(i32 64, i32 1, i32 0)
  ret void
}

declare i32 @llvm.amdgcn.workitem.id.x() #2
declare void @llvm.amdgcn.sched.group.barrier(i32, i32, i32) #1
declare <32 x float> @llvm.amdgcn.mfma.f32.32x32x1f32(float, float, <32 x float>, i32, i32, i32) #1

attributes #0 = { nounwind "amdgpu-flat-work-group-size"="1,256" }
attributes #1 = { nounwind }
attributes #2 = { nounwind readnone speculatable }


